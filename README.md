# 🧠 Vision Transformer (ViT) from Scratch

This repository implements the Vision Transformer (ViT) architecture from scratch using PyTorch. The goal is to build a transformer-based image classification model without relying on any high-level transformer libraries.

---

## 📸 What is a Vision Transformer?

The Vision Transformer (ViT) is a deep learning model that applies transformer architecture (originally designed for NLP) to image classification. Instead of using convolutions, images are split into patches and processed as a sequence, much like words in a sentence.

---

## 🏗️ Features

- ✔️ Custom implementation of Vision Transformer (ViT)
- ✔️ Patch embedding without CNNs
- ✔️ Multi-head Self-Attention from scratch
- ✔️ Positional embeddings
- ✔️ MLP classification head
- ✔️ Train & evaluate on CIFAR-10 or any other dataset

