# ğŸ§  Vision Transformer (ViT) from Scratch

This repository implements the Vision Transformer (ViT) architecture from scratch using PyTorch. The goal is to build a transformer-based image classification model without relying on any high-level transformer libraries.

---

## ğŸ“¸ What is a Vision Transformer?

The Vision Transformer (ViT) is a deep learning model that applies transformer architecture (originally designed for NLP) to image classification. Instead of using convolutions, images are split into patches and processed as a sequence, much like words in a sentence.

---

## ğŸ—ï¸ Features

- âœ”ï¸ Custom implementation of Vision Transformer (ViT)
- âœ”ï¸ Patch embedding without CNNs
- âœ”ï¸ Multi-head Self-Attention from scratch
- âœ”ï¸ Positional embeddings
- âœ”ï¸ MLP classification head
- âœ”ï¸ Train & evaluate on CIFAR-10 or any other dataset

